#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import requests
import time
import os
from datetime import datetime

def extract_next_page_token():
    """ì‹¤ì œ ìˆ˜ì§‘ëœ JSONì—ì„œ nextPageToken ì¶”ì¶œ"""
    
    print("ğŸ” ì‹¤ì œ JSON íŒŒì¼ì—ì„œ nextPageToken ì¶”ì¶œ ì¤‘...")
    
    # ìµœì‹  ë¹„ë””ì˜¤ ëª©ë¡ íŒŒì¼
    latest_file = "youtube_videos_list_20250724_142705.json"
    
    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # ì›ë³¸ ì „ì²´ ì‘ë‹µ í™•ì¸ (parse_and_save_video_dataì—ì„œ ì €ì¥ëœ êµ¬ì¡°)
        print(f"ğŸ“‚ íŒŒì¼ êµ¬ì¡° í™•ì¸:")
        for key in data.keys():
            print(f"   â€¢ {key}: {type(data[key])}")
        
        # ì‹¤ì œ nextPageToken ì°¾ê¸°
        next_token = None
        
        # ì—¬ëŸ¬ ìœ„ì¹˜ì—ì„œ nextPageToken ì°¾ê¸°
        if 'nextPageToken' in data:
            next_token = data['nextPageToken']
        elif 'original_response' in data and 'nextPageToken' in data['original_response']:
            next_token = data['original_response']['nextPageToken']
        
        if next_token:
            print(f"âœ… nextPageToken ë°œê²¬: {next_token}")
            return next_token, data
        else:
            print(f"âŒ nextPageTokenì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            # ì „ì²´ ë°ì´í„° êµ¬ì¡° ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            print(f"ì „ì²´ í‚¤ë“¤: {list(data.keys())}")
            return None, data
            
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return None, None

def get_captured_request_info():
    """ìº¡ì²˜ëœ ìš”ì²­ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    
    print("ğŸ” ìº¡ì²˜ëœ ìš”ì²­ ì •ë³´ í™•ì¸ ì¤‘...")
    
    # ìµœì‹  ë””ë²„ê·¸ íŒŒì¼ë“¤ ì°¾ê¸°
    debug_files = []
    for file in os.listdir('.'):
        if file.startswith('debug_request_') and file.endswith('.json'):
            debug_files.append(file)
    
    if not debug_files:
        print("âŒ ë””ë²„ê·¸ ìš”ì²­ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ê°€ì¥ ìµœì‹  íŒŒì¼ ì„ íƒ
    latest_debug = max(debug_files, key=lambda x: os.path.getmtime(x))
    print(f"ğŸ“‚ ìµœì‹  ë””ë²„ê·¸ íŒŒì¼: {latest_debug}")
    
    try:
        with open(latest_debug, 'r', encoding='utf-8') as f:
            debug_data = json.load(f)
        
        original_headers = debug_data.get('original_headers', {})
        curl_command = debug_data.get('curl_command', '')
        
        # URL ì¶”ì¶œ
        url = "https://studio.youtube.com/youtubei/v1/creator/list_creator_videos?alt=json"
        
        # ê¸°ë³¸ POST ë°ì´í„° ì¶”ì¶œ (curl ëª…ë ¹ì–´ì—ì„œ)
        if '--data-raw' in curl_command:
            data_start = curl_command.find("--data-raw '") + 12
            data_end = curl_command.find("'", data_start)
            
            if data_start > 11 and data_end > data_start:
                post_data = curl_command[data_start:data_end]
                
                try:
                    base_payload = json.loads(post_data)
                    print(f"âœ… ê¸°ë³¸ ìš”ì²­ í˜ì´ë¡œë“œ ì¶”ì¶œ ì™„ë£Œ")
                    return {
                        'url': url,
                        'headers': original_headers,
                        'base_payload': base_payload
                    }
                except json.JSONDecodeError:
                    print(f"âŒ POST ë°ì´í„° JSON íŒŒì‹± ì‹¤íŒ¨")
                    return None
        
        print(f"âŒ POST ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
        
    except Exception as e:
        print(f"âŒ ë””ë²„ê·¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return None

def collect_remaining_pages(next_token, request_info, existing_videos):
    """ë‚¨ì€ ëª¨ë“  í˜ì´ì§€ ìˆ˜ì§‘"""
    
    print(f"\nğŸš€ ë‚¨ì€ í˜ì´ì§€ë“¤ ìë™ ìˆ˜ì§‘ ì‹œì‘!")
    print(f"ğŸ¯ ì‹œì‘ í† í°: {next_token[:50]}...")
    
    all_videos = existing_videos.copy()  # ê¸°ì¡´ ë¹„ë””ì˜¤ë“¤ ë³µì‚¬
    page_count = 1  # ì´ë¯¸ ì²« í˜ì´ì§€ëŠ” ìˆ˜ì§‘ë¨
    current_token = next_token
    
    while current_token:
        page_count += 1
        print(f"\nğŸ“„ í˜ì´ì§€ {page_count} ìˆ˜ì§‘ ì¤‘...")
        
        # í˜ì´ë¡œë“œì— pageToken ì¶”ê°€
        payload = request_info['base_payload'].copy()
        payload['pageToken'] = current_token
        
        # ìš”ì²­ ì „ì†¡
        session = requests.Session()
        headers = request_info['headers'].copy()
        
        # ì¿ í‚¤ ì„¤ì •
        if 'Cookie' in headers:
            cookie_str = headers['Cookie']
            cookies = {}
            for item in cookie_str.split(';'):
                if '=' in item:
                    key, value = item.strip().split('=', 1)
                    cookies[key] = value
            session.cookies.update(cookies)
            print(f"   ğŸª ì¿ í‚¤ ì„¤ì •: {len(cookies)}ê°œ")
        
        # Content-Length ì œê±°
        headers.pop('Content-Length', None)
        
        try:
            print(f"   ğŸ“¡ API ìš”ì²­ ì „ì†¡ ì¤‘...")
            response = session.post(
                request_info['url'], 
                headers=headers, 
                json=payload, 
                timeout=30
            )
            
            print(f"   ğŸ“¨ ì‘ë‹µ ìˆ˜ì‹ : {response.status_code}")
            
            if response.status_code == 200:
                api_response = response.json()
                
                # ì´ í˜ì´ì§€ì˜ ë¹„ë””ì˜¤ë“¤ ì¶”ê°€
                page_videos = api_response.get('videos', [])
                print(f"   âœ… í˜ì´ì§€ {page_count}: {len(page_videos)}ê°œ ë¹„ë””ì˜¤ ìˆ˜ì§‘")
                
                # ê³µê°œ ì˜ìƒë§Œ í•„í„°ë§
                public_videos = []
                for video in page_videos:
                    if video.get('privacy') == 'VIDEO_PRIVACY_PUBLIC':
                        public_videos.append(video)
                
                print(f"   ğŸ“º ê³µê°œ ì˜ìƒ: {len(public_videos)}ê°œ")
                all_videos.extend(public_videos)
                
                # ë‹¤ìŒ í˜ì´ì§€ í† í° í™•ì¸
                current_token = api_response.get('nextPageToken')
                if current_token:
                    print(f"   ğŸ”„ ë‹¤ìŒ í˜ì´ì§€ í† í°: {current_token[:50]}...")
                else:
                    print(f"   ğŸ ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬!")
                    break
                    
            else:
                print(f"   âŒ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
                print(f"   ì‘ë‹µ: {response.text[:200]}...")
                break
                
        except Exception as e:
            print(f"   âŒ ìš”ì²­ ì˜¤ë¥˜: {e}")
            break
        
        # API ì œí•œ ê³ ë ¤
        time.sleep(1)
    
    print(f"\nğŸ‰ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ!")
    print(f"   ğŸ“„ ì´ í˜ì´ì§€: {page_count}ê°œ")
    print(f"   ğŸ“¹ ì´ ê³µê°œ ë¹„ë””ì˜¤: {len(all_videos)}ê°œ")
    
    return all_videos, page_count

def save_complete_data(all_videos, page_count):
    """ì™„ì „í•œ ë°ì´í„° ì €ì¥"""
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # JSON ì €ì¥
    json_filename = f"youtube_videos_COMPLETE_{timestamp}.json"
    complete_data = {
        'collection_method': 'manual_pagination',
        'total_pages_collected': page_count,
        'total_videos': len(all_videos),
        'collected_at': datetime.now().isoformat(),
        'videos': all_videos
    }
    
    with open(json_filename, 'w', encoding='utf-8') as f:
        json.dump(complete_data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ ì™„ì „í•œ ë°ì´í„° ì €ì¥:")
    print(f"   ğŸ“„ JSON: {json_filename}")
    
    return json_filename

def main():
    print("ğŸ¯ nextPageTokenì„ ì‚¬ìš©í•œ ì „ì²´ ë¹„ë””ì˜¤ ìˆ˜ì§‘")
    print("="*70)
    
    # 1ë‹¨ê³„: nextPageToken ì¶”ì¶œ
    next_token, existing_data = extract_next_page_token()
    
    if not next_token:
        print(f"âŒ nextPageTokenì„ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ğŸ’¡ ë¸Œë¼ìš°ì €ì—ì„œ ê°•ë ¥ ìƒˆë¡œê³ ì¹¨ í›„ python once.pyë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ë³´ì„¸ìš”.")
        return
    
    # 2ë‹¨ê³„: ìº¡ì²˜ëœ ìš”ì²­ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    request_info = get_captured_request_info()
    
    if not request_info:
        print(f"âŒ ìº¡ì²˜ëœ ìš”ì²­ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 3ë‹¨ê³„: ê¸°ì¡´ ë¹„ë””ì˜¤ë“¤ ê°€ì ¸ì˜¤ê¸°
    existing_videos = existing_data.get('videos', [])
    print(f"ğŸ“‹ ê¸°ì¡´ ìˆ˜ì§‘ëœ ê³µê°œ ë¹„ë””ì˜¤: {len(existing_videos)}ê°œ")
    
    # 4ë‹¨ê³„: ë‚¨ì€ í˜ì´ì§€ë“¤ ìˆ˜ì§‘
    complete_videos, total_pages = collect_remaining_pages(
        next_token, request_info, existing_videos
    )
    
    # 5ë‹¨ê³„: ì™„ì „í•œ ë°ì´í„° ì €ì¥
    if len(complete_videos) > len(existing_videos):
        saved_file = save_complete_data(complete_videos, total_pages)
        
        print(f"\nğŸ‰ ë¯¸ì…˜ ì™„ë£Œ!")
        print(f"   ğŸ“ˆ ê¸°ì¡´: {len(existing_videos)}ê°œ â†’ ìµœì¢…: {len(complete_videos)}ê°œ")
        print(f"   ğŸ“‚ ì™„ì „í•œ íŒŒì¼: {saved_file}")
        print(f"\nğŸ’¡ ì´ì œ ì´ ë°ì´í„°ë¡œ ì• ë„ë¦¬í‹±ìŠ¤ ìˆ˜ì§‘ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    else:
        print(f"âš ï¸ ì¶”ê°€ë¡œ ìˆ˜ì§‘ëœ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 